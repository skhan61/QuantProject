{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 10**3)\n",
    "pd.set_option('display.max_rows', 10**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import gc\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from sklearn.preprocessing import scale\n",
    "import talib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import alphalens\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/YEAR_20130102_20141209', '/data/YEAR_20141210_20161115', '/data/YEAR_20161116_20181023', '/data/YEAR_20181024_20200929', '/data/YEAR_20200930_20220802']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from utils import rank_stocks_and_quantile\n",
    "# UNSEEN_KEY = '/data/YEAR_20220803_20230803'\n",
    "top = 250  # parameters -> papermill\n",
    "DATA_STORE = Path(f'data/{top}_dataset.h5')\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    # unseen = store[UNSEEN_KEY]\n",
    "    print(store.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 117250 entries, (Timestamp('2020-09-30 00:00:00+0000', tz='UTC'), 'AA') to (Timestamp('2022-08-02 00:00:00+0000', tz='UTC'), 'ZTS')\n",
      "Columns: 600 entries, FEATURE_open to TARGET_ret_fwd_01d_rank_quantiled\n",
      "dtypes: float32(360), float64(32), int32(198), int64(1), int8(9)\n",
      "memory usage: 280.6+ MB\n",
      "None\n",
      "586\n",
      "TARGET_ret_fwd_01d_rank_quantiled\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from utils import rank_stocks_and_quantile\n",
    "\n",
    "top = 250  # parameters -> papermill\n",
    "DATA_STORE = Path(f'data/{top}_dataset.h5')\n",
    "dataset_key = '/data/YEAR_20200930_20220802'\n",
    "label_col = 'TARGET_ret_fwd_01d' \n",
    "label = label_col + '_rank_quantiled'\n",
    "\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    dataset = store[dataset_key]\n",
    "    # print(dataset.index.levels[datetime_level].tz)\n",
    "\n",
    "# Check and localize the datetime level of the MultiIndex to UTC if needed\n",
    "datetime_level = 0  # Assuming the datetime is the first level\n",
    "if dataset.index.levels[datetime_level].tz is None:\n",
    "    localized_level = dataset.index.levels[datetime_level].tz_localize('UTC')\n",
    "    dataset.index = dataset.index.set_levels(localized_level, level=datetime_level)\n",
    "\n",
    "# Applying the rank_stocks_and_quantile function to the dataset\n",
    "dataset_ranked = rank_stocks_and_quantile(dataset, TARGET_col=label_col)\n",
    "print(dataset_ranked.info())\n",
    "\n",
    "del dataset\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "cols = dataset_ranked.columns.tolist()\n",
    "# Populate the features list with column names starting with 'feature_'\n",
    "features = [col for col in cols if col.startswith('FEATURE_')]\n",
    "# Find the first column starting with 'target_' and set it as the label\n",
    "label_cols = [col for col in cols if col.startswith('TARGET_')]\n",
    "print(len(features))  # This will show all the columns starting with 'feature_'\n",
    "print(label)  # This will show the first column starting with 'target_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'TARGET_ret_fwd_frac_order'\n",
    "# # Assuming you have your original dataframe named df ready\n",
    "# alphalens_analysis = generate_alphalens_tearsheet(dataset_ranked, \\\n",
    "#     label_col=target, price_col='FEATURE_close')\n",
    "\n",
    "\n",
    "# # alphalens_analysis\n",
    "# import alphalens as al\n",
    "# al.tears.create_full_tear_sheet(alphalens_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ranked.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Idea: Convrting returns as a image shapshot: IPCV project\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Assuming 'dataset_ranked' is your dataframe and has already been loaded into the current workspace.\n",
    "unique_dates = dataset_ranked.index.get_level_values(0).unique()\n",
    "\n",
    "images = []\n",
    "\n",
    "# Determine the dimensions of the 2D image based on the number of tickers.\n",
    "num_tickers = len(dataset_ranked.index.get_level_values(1).unique())\n",
    "side_length = math.floor(math.sqrt(num_tickers))  # Largest square less than num_tickers\n",
    "\n",
    "# Adjust the number of tickers\n",
    "num_tickers = side_length * side_length\n",
    "\n",
    "for idx, date in enumerate(unique_dates):\n",
    "    day_data = dataset_ranked.loc[date].iloc[:num_tickers]  # Keep only the number of rows we need\n",
    "    \n",
    "    if all(feature in day_data.columns for feature in \\\n",
    "        ['FEATURE_ret_frac_order', 'FEATURE_ret_01d', 'FEATURE_ret_02d']):\n",
    "        \n",
    "        channels = []\n",
    "        \n",
    "        for feature in ['FEATURE_ret_frac_order', 'FEATURE_ret_01d', 'FEATURE_ret_02d']:\n",
    "            # Convert the data to a 2D image representation\n",
    "            feature_data = day_data[feature].values\n",
    "            # Reshape it to a square matrix\n",
    "            feature_image = feature_data.reshape(side_length, side_length)\n",
    "            channels.append(feature_image)\n",
    "        \n",
    "        # Stack the channels to form a multi-channel image\n",
    "        image = np.stack(channels, axis=-1)\n",
    "        images.append(image)\n",
    "    else:\n",
    "        print(f\"Skipping date {date} due to inadequate data.\")\n",
    "\n",
    "print(\"Number of images:\", len(images))\n",
    "if images:\n",
    "    print(images[0].shape)  # This should give (side_length, side_length, 3)\n",
    "else:\n",
    "    print(\"No images created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Get the first image from the images list\n",
    "first_image = images[0]\n",
    "\n",
    "# Scale it to 0-255 range for visualization (useful if your data isn't already in this range)\n",
    "scaled_image = (first_image - first_image.min()) / (first_image.max() - first_image.min()) * 255\n",
    "scaled_image = scaled_image.astype(np.uint8)\n",
    "\n",
    "# Create a PIL image\n",
    "image_pil = Image.fromarray(scaled_image)\n",
    "\n",
    "# Display the image\n",
    "image_pil.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "\n",
    "display(image_pil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
