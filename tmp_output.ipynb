{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d58b5e6",
   "metadata": {
    "papermill": {
     "duration": 0.001399,
     "end_time": "2023-10-07T14:02:02.915137",
     "exception": false,
     "start_time": "2023-10-07T14:02:02.913738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0d0222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T14:02:02.925791Z",
     "iopub.status.busy": "2023-10-07T14:02:02.925527Z",
     "iopub.status.idle": "2023-10-07T14:02:04.233064Z",
     "shell.execute_reply": "2023-10-07T14:02:04.232675Z"
    },
    "papermill": {
     "duration": 1.310051,
     "end_time": "2023-10-07T14:02:04.233997",
     "exception": false,
     "start_time": "2023-10-07T14:02:02.923946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# Index and deciles for data slicing\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bc2a4",
   "metadata": {
    "papermill": {
     "duration": 0.008867,
     "end_time": "2023-10-07T14:02:04.244886",
     "exception": false,
     "start_time": "2023-10-07T14:02:04.236019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Test on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f187e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T14:02:04.248909Z",
     "iopub.status.busy": "2023-10-07T14:02:04.248730Z",
     "iopub.status.idle": "2023-10-07T14:02:06.061945Z",
     "shell.execute_reply": "2023-10-07T14:02:06.061547Z"
    },
    "papermill": {
     "duration": 1.815981,
     "end_time": "2023-10-07T14:02:06.062529",
     "exception": false,
     "start_time": "2023-10-07T14:02:04.246548",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 129220 entries, ('AA', Timestamp('2022-08-05 00:00:00')) to ('ZTS', Timestamp('2023-08-03 00:00:00'))\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   actual          129220 non-null  float64\n",
      " 1   predicted       129220 non-null  float64\n",
      " 2   FEATURE_open    129220 non-null  float32\n",
      " 3   FEATURE_high    129220 non-null  float32\n",
      " 4   FEATURE_low     129220 non-null  float32\n",
      " 5   FEATURE_close   129220 non-null  float32\n",
      " 6   FEATURE_volume  129220 non-null  float64\n",
      "dtypes: float32(4), float64(3)\n",
      "memory usage: 5.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from utils import rank_stocks_and_quantile\n",
    "\n",
    "def load_model_and_parameters(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "    return loaded_object['model'], loaded_object['params']\n",
    "\n",
    "def read_and_process_data(store_path, key, target_substring):\n",
    "    with pd.HDFStore(store_path) as store:\n",
    "        data = store[key]\n",
    "    data = rank_stocks_and_quantile(data, target_substring=target_substring)\n",
    "    new_index = data.index.set_levels(data.index.levels[0].tz_localize(None), level=0)\n",
    "    data.set_index(new_index, inplace=True)\n",
    "    return data\n",
    "\n",
    "def filter_by_date(data, look_ahead):\n",
    "    unique_dates = data.index.get_level_values('date').unique().sort_values()\n",
    "    assert len(unique_dates) > look_ahead, f\"Insufficient unique dates for a look_ahead value of {look_ahead}\"\n",
    "    cut_off_date = unique_dates[look_ahead]\n",
    "    return data[data.index.get_level_values('date') > cut_off_date]\n",
    "\n",
    "def synchronize_and_merge_predictions(data, features, model, label):\n",
    "    y_pred = model.predict(data[features])\n",
    "    synchronized_labels = data[label][data[label].index.isin(data[features].index)]\n",
    "    synchronized_y_pred = y_pred[:len(synchronized_labels)]\n",
    "\n",
    "    preds = synchronized_labels.reset_index(name='actual').assign(predicted=synchronized_y_pred).set_index(['date', 'ticker'])\n",
    "    cols_to_rename = ['open', 'high', 'low', 'close', 'volume']\n",
    "    new_col_names = [\"FEATURE_\" + col for col in cols_to_rename]\n",
    "    rename_dict = dict(zip(cols_to_rename, new_col_names))\n",
    "    data_renamed = data.rename(columns=rename_dict)\n",
    "    preds = preds.reset_index().merge(data_renamed[new_col_names].reset_index(), on=['ticker', 'date'], how='left')\n",
    "    return preds[['date', 'ticker', 'actual', 'predicted'] + new_col_names].set_index(['ticker', 'date'])\n",
    "\n",
    "def main_execution(TOP):\n",
    "    UNSEEN_KEY = '/data/YEAR_20220803_20230803'\n",
    "    UNSEEN_STORE = Path(f'data/{TOP}_unseen_dataset.h5')\n",
    "    \n",
    "    # First, define the MODEL_PATH\n",
    "    MODEL_PATH = f\"/home/sayem/Desktop/Project/models/{TOP}_combined_model_and_params_TARGET_ret_fwd_01d_rank_quantiled.pkl\"\n",
    "    \n",
    "    # Then, use the MODEL_PATH to load the model and its parameters\n",
    "    best_model, params = load_model_and_parameters(MODEL_PATH)\n",
    "    lookahead = params.get('look_ahead', 1)  # Fetching the best look ahead from params\n",
    "\n",
    "    test_data = read_and_process_data(UNSEEN_STORE, UNSEEN_KEY, 'TARGET_ret_fwd_')\n",
    "    filtered_test_data = filter_by_date(test_data, lookahead)\n",
    "    label = f'TARGET_ret_fwd_{lookahead:02d}d_rank_quantiled'\n",
    "    features = [col for col in test_data.columns if col.startswith('FEATURE_')]\n",
    "    preds = synchronize_and_merge_predictions(filtered_test_data, features, best_model, label)\n",
    "    return preds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    top = TOP = 500\n",
    "    preds = main_execution(TOP)\n",
    "    print(preds.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f515203b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T14:02:06.065447Z",
     "iopub.status.busy": "2023-10-07T14:02:06.065357Z",
     "iopub.status.idle": "2023-10-07T14:02:06.067065Z",
     "shell.execute_reply": "2023-10-07T14:02:06.066812Z"
    },
    "papermill": {
     "duration": 0.003511,
     "end_time": "2023-10-07T14:02:06.067512",
     "exception": false,
     "start_time": "2023-10-07T14:02:06.064001",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "top = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1d1b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T14:02:06.069848Z",
     "iopub.status.busy": "2023-10-07T14:02:06.069607Z",
     "iopub.status.idle": "2023-10-07T14:02:06.087386Z",
     "shell.execute_reply": "2023-10-07T14:02:06.087120Z"
    },
    "papermill": {
     "duration": 0.01945,
     "end_time": "2023-10-07T14:02:06.087867",
     "exception": false,
     "start_time": "2023-10-07T14:02:06.068417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Coefficient (overall): 3.094% (p-value: 0.00000000%)\n"
     ]
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.030940046709680088,
       "encoder": "json",
       "name": "information_coefficient",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "information_coefficient"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.030940046709680088"
      ]
     },
     "metadata": {
      "scrapbook": {
       "data": false,
       "display": true,
       "name": "information_coefficient"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 9.519909440336237e-29,
       "encoder": "json",
       "name": "p_value",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "p_value"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9.519909440336237e-29"
      ]
     },
     "metadata": {
      "scrapbook": {
       "data": false,
       "display": true,
       "name": "p_value"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "lr_r, lr_p = spearmanr(preds.actual, preds.predicted)\n",
    "print(f'Information Coefficient (overall): {lr_r:.3%} (p-value: {lr_p:.8%})')\n",
    "\n",
    "# Return the Information Coefficient and its p-value\n",
    "information_coefficient = lr_r\n",
    "p_value = lr_p\n",
    "\n",
    "# information_coefficient = papermill_information_coefficient, p_value = papermill_p_value\n",
    "sb.glue(\"information_coefficient\", information_coefficient, display=True)\n",
    "sb.glue(\"p_value\", p_value, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c5f8fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T14:02:06.090625Z",
     "iopub.status.busy": "2023-10-07T14:02:06.090547Z",
     "iopub.status.idle": "2023-10-07T14:02:06.094567Z",
     "shell.execute_reply": "2023-10-07T14:02:06.094316Z"
    },
    "papermill": {
     "duration": 0.005906,
     "end_time": "2023-10-07T14:02:06.095032",
     "exception": false,
     "start_time": "2023-10-07T14:02:06.089126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 129220 entries, ('AA', Timestamp('2022-08-05 00:00:00')) to ('ZTS', Timestamp('2023-08-03 00:00:00'))\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   actual          129220 non-null  float64\n",
      " 1   predicted       129220 non-null  float64\n",
      " 2   FEATURE_open    129220 non-null  float32\n",
      " 3   FEATURE_high    129220 non-null  float32\n",
      " 4   FEATURE_low     129220 non-null  float32\n",
      " 5   FEATURE_close   129220 non-null  float32\n",
      " 6   FEATURE_volume  129220 non-null  float64\n",
      "dtypes: float32(4), float64(3)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "preds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b5d7c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T14:02:06.098010Z",
     "iopub.status.busy": "2023-10-07T14:02:06.097772Z",
     "iopub.status.idle": "2023-10-07T14:02:06.104601Z",
     "shell.execute_reply": "2023-10-07T14:02:06.104348Z"
    },
    "papermill": {
     "duration": 0.008778,
     "end_time": "2023-10-07T14:02:06.105059",
     "exception": false,
     "start_time": "2023-10-07T14:02:06.096281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_quantile_signals(df, col_name='predicted', buy_threshold=0.8, sell_threshold=0.1):\n",
    "    buy_cutoff = df[col_name].quantile(buy_threshold)\n",
    "    sell_cutoff = df[col_name].quantile(sell_threshold)\n",
    "    \n",
    "    # Create a new column for signals\n",
    "    df['signal'] = 0  # Neutral by default\n",
    "    df.loc[df[col_name] >= buy_cutoff, 'signal'] = 1  # Buy\n",
    "    df.loc[df[col_name] <= sell_cutoff, 'signal'] = -1  # Sell\n",
    "    return df\n",
    "\n",
    "# Apply the function ## Testing\n",
    "preds = add_quantile_signals(preds.copy(), buy_threshold=0.95, sell_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6fc631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T14:02:06.107904Z",
     "iopub.status.busy": "2023-10-07T14:02:06.107725Z",
     "iopub.status.idle": "2023-10-07T14:02:06.111659Z",
     "shell.execute_reply": "2023-10-07T14:02:06.111396Z"
    },
    "papermill": {
     "duration": 0.005802,
     "end_time": "2023-10-07T14:02:06.112058",
     "exception": false,
     "start_time": "2023-10-07T14:02:06.106256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 129220 entries, ('AA', Timestamp('2022-08-05 00:00:00')) to ('ZTS', Timestamp('2023-08-03 00:00:00'))\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   actual          129220 non-null  float64\n",
      " 1   predicted       129220 non-null  float64\n",
      " 2   FEATURE_open    129220 non-null  float32\n",
      " 3   FEATURE_high    129220 non-null  float32\n",
      " 4   FEATURE_low     129220 non-null  float32\n",
      " 5   FEATURE_close   129220 non-null  float32\n",
      " 6   FEATURE_volume  129220 non-null  float64\n",
      " 7   signal          129220 non-null  int64  \n",
      "dtypes: float32(4), float64(3), int64(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "preds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a93cd4",
   "metadata": {
    "papermill": {
     "duration": 0.001626,
     "end_time": "2023-10-07T14:02:06.115062",
     "exception": false,
     "start_time": "2023-10-07T14:02:06.113436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a04ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-10-07T14:02:06.116607",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "import backtrader.analyzers as btanalyzers\n",
    "from pypfopt import EfficientFrontier, expected_returns, risk_models\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "\n",
    "import quantstats as qs\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "qs.extend_pandas()\n",
    "\n",
    "# Data Class for Predictions\n",
    "class PandasPredictions(bt.feeds.PandasData):\n",
    "    lines = ('signal',)\n",
    "    params = (\n",
    "        ('signal', -1),\n",
    "        ('open', 'FEATURE_open'),\n",
    "        ('high', 'FEATURE_high'),\n",
    "        ('low', 'FEATURE_low'),\n",
    "        ('close', 'FEATURE_close'),\n",
    "        ('volume', 'FEATURE_volume')\n",
    "    )\n",
    "\n",
    "# Function to optimize weights using PyPortfolioOpt\n",
    "def optimize_weights(datas):\n",
    "    prices = {}\n",
    "    for data in datas:\n",
    "        s = pd.Series(data.close.array, index=data.datetime.array, name=data._name)\n",
    "        s = s.groupby(s.index).first()  # This will drop duplicate datetime entries, if any\n",
    "        prices[data._name] = s\n",
    "    df = pd.concat(prices, axis=1).dropna()\n",
    "\n",
    "    mu = expected_returns.mean_historical_return(df)\n",
    "    S_original = risk_models.sample_cov(df)\n",
    "    S = (1 - 0.05) * S_original + 0.05 * np.eye(S_original.shape[0])\n",
    "    S += 1e-6 * np.eye(S_original.shape[0])\n",
    "    \n",
    "    ef = EfficientFrontier(mu, S, solver=\"SCS\", verbose=False)\n",
    "    try:\n",
    "        weights = ef.max_sharpe(risk_free_rate=0.005)\n",
    "    except ValueError as e:\n",
    "        if \"expected return exceeding the risk-free rate\" in str(e):\n",
    "            print(\"Using alternative method due to low expected returns.\")\n",
    "            weights = ef.min_volatility()  # or any other method you'd prefer\n",
    "        else:\n",
    "            raise e\n",
    "    # weights = ef.max_sharpe(risk_free_rate=0.005)\n",
    "    return weights\n",
    "\n",
    "# Strategy Class\n",
    "class TradeAndRebalanceStrategy(bt.Strategy):    \n",
    "    params = {'stop_loss': 0.05, 'take_profit': 0.10, \\\n",
    "        'max_loss': -0.2, 'rebalance_days_interval': 20}\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rebalance_days = 0\n",
    "        self.start_cash = self.broker.get_cash()\n",
    "        self.orders = {}  \n",
    "        self.atr_dict = {data: btind.ATR(data) for data in self.datas}\n",
    "\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status == order.Completed and order.ref in self.orders:\n",
    "            del self.orders[order.ref]\n",
    "\n",
    "    def next(self):        \n",
    "        for data in self.datas:\n",
    "            atr_value = self.atr_dict.get(data, 0)[0]\n",
    "            if data.signal[0] == 1:\n",
    "                order = self.buy(data)\n",
    "                self.orders[order.ref] = order\n",
    "                stop_price = data.close[0] - atr_value * 2\n",
    "                limit_price = data.close[0] + atr_value * 2\n",
    "                self.sell(data=data, exectype=bt.Order.Stop, price=stop_price, parent=order.ref)\n",
    "                self.sell(data=data, exectype=bt.Order.Limit, price=limit_price, parent=order.ref)\n",
    "            elif data.signal[0] == -1:\n",
    "                self.sell(data)\n",
    "\n",
    "        if not self.rebalance_days:\n",
    "            weights = optimize_weights(self.datas)\n",
    "            weights = {k: min(v, 0.30) for k, v in weights.items()}\n",
    "            for data in self.datas:\n",
    "                self.order_target_percent(data, target=weights.get(data._name, 0))\n",
    "            self.rebalance_days = self.params.rebalance_days_interval\n",
    "        else:\n",
    "            self.rebalance_days -= 1\n",
    "\n",
    "# Setup\n",
    "cerebro = bt.Cerebro()\n",
    "cerebro.broker.setcommission(commission=0.001)\n",
    "cerebro.addanalyzer(btanalyzers.PyFolio, _name='pyfolio')\n",
    "\n",
    "data_dict = {ticker: preds.xs(ticker) for ticker in \\\n",
    "    preds.index.get_level_values(0).unique()}\n",
    "for ticker, data_df in data_dict.items():\n",
    "    data = PandasPredictions(dataname=data_df, name=ticker)\n",
    "    cerebro.adddata(data)\n",
    "\n",
    "# # Assuming you want to test max_loss values of -0.1, -0.2, and -0.3\n",
    "cerebro.optstrategy(TradeAndRebalanceStrategy, \n",
    "                    stop_loss=[0.03, 0.05, 0.07], \n",
    "                    take_profit=[0.10, 0.12, 0.14],\n",
    "                    max_loss=[-0.1, -0.2, -0.3],\n",
    "                    rebalance_days_interval=[10, 20, 30])  # Example range of values\n",
    "\n",
    "# cerebro.optstrategy(TradeAndRebalanceStrategy, \n",
    "#                     stop_loss=[0.03, 0.5 ], \n",
    "#                     take_profit=[0.10, 0.12])\n",
    "#                     # max_loss=[-0.1],\n",
    "#                     # rebalance_days_interval=[10])  # Example range of values\n",
    "\n",
    "results = cerebro.run(maxcpus=1) # <= uncomment to run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6041ed3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import quantstats as qs\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "RISK_FREE_RATE = 0.0  # Annualized risk-free rate\n",
    "BENCHMARK_TICKER = \"SPY\"\n",
    "STRATEGY = \"Strategy\"\n",
    "top = TOP  # Placeholder, replace with appropriate value if \"TOP\" is not the desired string\n",
    "OUTPUT_REPORT_PATH = f\"report/{top}_strategy_report.html\"\n",
    "\n",
    "# Ensure directory exists\n",
    "directory_path = f'backtest_results/{top}'\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "def calculate_strategy_metrics(results):\n",
    "    metrics_dict = {}\n",
    "    best_returns = None\n",
    "    best_params_str = None\n",
    "    all_returns = {}\n",
    "\n",
    "    for res in results:\n",
    "        for r in res:\n",
    "            params_str = ', '.join([f\"{k}={v}\" for k, v in r.params._getitems()])\n",
    "            returns, _, _, _ = r.analyzers.pyfolio.get_pf_items()\n",
    "            daily_returns = returns.resample('D').sum()\n",
    "            all_returns[params_str] = daily_returns\n",
    "\n",
    "            sharpe_ratio = qs.stats.sharpe(daily_returns, rf=RISK_FREE_RATE)\n",
    "            drawdown = qs.stats.max_drawdown(daily_returns)\n",
    "            metrics_dict[params_str] = (sharpe_ratio, drawdown)\n",
    "\n",
    "            if not best_params_str or (sharpe_ratio > metrics_dict[best_params_str][0]\n",
    "                                       and drawdown > metrics_dict[best_params_str][1]):\n",
    "                best_params_str = params_str\n",
    "                best_returns = daily_returns\n",
    "\n",
    "    return best_returns, all_returns\n",
    "\n",
    "def setup_data_for_reporting(best_returns):\n",
    "    if best_returns.index.tzinfo:\n",
    "        best_returns.index = best_returns.index.tz_convert('UTC')\n",
    "    else:\n",
    "        best_returns.index = best_returns.index.tz_localize('UTC')\n",
    "\n",
    "    benchmark_data = yf.download(BENCHMARK_TICKER, \\\n",
    "        start=best_returns.index.min(), end=best_returns.index.max())\n",
    "    benchmark = benchmark_data['Adj Close'].pct_change().dropna()\n",
    "\n",
    "    best_returns.name = STRATEGY\n",
    "    benchmark.name = BENCHMARK_TICKER\n",
    "\n",
    "    benchmark.index = benchmark.index.tz_localize('UTC')\n",
    "    best_returns.index = best_returns.index.tz_localize(None)\n",
    "    benchmark.index = benchmark.index.tz_localize(None)\n",
    "\n",
    "    return best_returns, benchmark\n",
    "\n",
    "def report_and_visualize_strategy_performance(best_returns, benchmark):\n",
    "    print(\"Sharpe Ratio for the strategy:\", qs.stats.sharpe(best_returns))\n",
    "    qs.plots.snapshot(best_returns, title='Strategy Performance', show=True)\n",
    "    qs.reports.html(best_returns, benchmark=benchmark, \\\n",
    "        title=\"Strategy Tearsheet\", output=OUTPUT_REPORT_PATH)\n",
    "\n",
    "def main():\n",
    "    best_returns, all_strategy_returns = calculate_strategy_metrics(results)\n",
    "\n",
    "    if best_returns is None:\n",
    "        print(\"Couldn't extract results for the strategies.\")\n",
    "        return\n",
    "\n",
    "    df = best_returns, benchmark = setup_data_for_reporting(best_returns)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "    qs.extend_pandas()\n",
    "    report_and_visualize_strategy_performance(best_returns, benchmark)\n",
    "\n",
    "    return best_returns\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_returns = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58fe201",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "08_strategy_building_and_backtesting.ipynb",
   "output_path": "tmp_output.ipynb",
   "parameters": {
    "top": 250
   },
   "start_time": "2023-10-07T14:02:02.227008",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}