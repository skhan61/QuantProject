{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# Index and deciles for data slicing\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from utils import rank_stocks_and_quantile\n",
    "\n",
    "target = 'TARGET_ret_fwd_frac_order'\n",
    "top = 250  \n",
    "unseen_key = '/data/YEAR_20220803_20230803'\n",
    "unseen_store_path = Path(f'data/{top}_unseen_dataset.h5')\n",
    "\n",
    "# Load dataset and rank stocks\n",
    "with pd.HDFStore(unseen_store_path) as store:\n",
    "    dataset = store[unseen_key]\n",
    "    dataset_ranked = rank_stocks_and_quantile(dataset, target)\n",
    "\n",
    "# Localize datetime index if not already done\n",
    "datetime_level = 0  # Assuming the datetime is the first level\n",
    "if dataset_ranked.index.levels[datetime_level].tz is None:\n",
    "    localized_level = dataset_ranked.index.levels[datetime_level].tz_localize('UTC')\n",
    "    dataset_ranked.index = dataset_ranked.index.set_levels(localized_level, level=datetime_level)\n",
    "\n",
    "# Get unique dates and sort them\n",
    "unique_dates = dataset_ranked.index.get_level_values('date').unique().sort_values()\n",
    "\n",
    "# Extract feature columns and label columns\n",
    "features = [col for col in dataset_ranked.columns if col.startswith('FEATURE_')]\n",
    "label_cols = [col for col in dataset_ranked.columns if col.startswith('TARGET_')]\n",
    "\n",
    "# Adjust for the look-ahead gap and get test dates\n",
    "look_ahead = 1\n",
    "test_dates = unique_dates[-21*9:]\n",
    "\n",
    "# Extract the test data subset\n",
    "test_data = dataset_ranked[dataset_ranked.index.isin(test_dates, level='date')]\n",
    "\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "def predict_and_format(model_path: str, \\\n",
    "                    test_data: pd.DataFrame, \\\n",
    "                    features: list, label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a LightGBM model from the specified path, make predictions on the test data, and format the results.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: Path to the saved LightGBM model.\n",
    "    - test_data: Test dataframe containing features and labels.\n",
    "    - features: List of feature column names.\n",
    "    - label: Column name of the label.\n",
    "\n",
    "    Returns:\n",
    "    - preds: Formatted dataframe with predictions and selected feature data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the model\n",
    "    best_model = lgb.Booster(model_file=model_path)\n",
    "\n",
    "    # Extract features and labels\n",
    "    test_features = test_data[features]\n",
    "    test_labels = test_data[label]\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(test_features)\n",
    "\n",
    "    # Format the predictions dataframe\n",
    "    preds = test_labels.reset_index(name='actual').assign(predicted=\\\n",
    "        y_pred).set_index(['date', 'ticker'])\n",
    "\n",
    "    # Rename columns to add 'feature_' prefix\n",
    "    cols_to_rename = ['open', 'high', 'low', 'close', 'volume']\n",
    "    new_col_names = [\"FEATURE_\" + col for col in cols_to_rename]\n",
    "    rename_dict = dict(zip(cols_to_rename, new_col_names))\n",
    "\n",
    "    test_data_renamed = test_data.rename(columns=rename_dict)\n",
    "\n",
    "    # Join with selected feature data\n",
    "    preds = preds.reset_index().merge(test_data_renamed[new_col_names].reset_index(), \n",
    "                                      on=['ticker', 'date'], \n",
    "                                      how='left')\n",
    "\n",
    "    # Filter columns of interest\n",
    "    preds = preds[['date', 'ticker', 'actual', 'predicted'] + new_col_names].set_index(['ticker', 'date'])\n",
    "    \n",
    "    return preds\n",
    "\n",
    "model_path = \"/home/sayem/Desktop/Project/models/_data_YEAR_20200930_20220802_best_model.txt\"\n",
    "preds = predict_and_format(model_path, test_data, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_spearman(group):\n",
    "    return spearmanr(group['actual'], group['predicted'])[0]\n",
    "\n",
    "daily_correlations = preds.groupby('date').apply(daily_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of daily correlations\n",
    "mean_daily_correlation = daily_correlations.mean()\n",
    "std_daily_correlation = daily_correlations.std()\n",
    "\n",
    "# Calculate Sharpe ratio for each date\n",
    "papermill_era_scores = daily_sharpe_ratios = (daily_correlations - \\\n",
    "    mean_daily_correlation) / std_daily_correlation\n",
    "\n",
    "papermill_era_scores_df = papermill_era_scores.to_frame()\n",
    "papermill_era_scores_df.columns = papermill_era_scores_df.columns.astype(str)\n",
    "sb.glue(\"papermill_era_scores\", papermill_era_scores_df, display=True)\n",
    "\n",
    "papermill_era_scores_list = papermill_era_scores.tolist()\n",
    "sb.glue(\"papermill_era_scores\", papermill_era_scores_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Create a list of colors based on the sign of the Sharpe Ratios\n",
    "# colors = ['blue' if value > 0 else 'red' for value in daily_sharpe_ratios]\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# daily_sharpe_ratios.plot(kind='bar', color=colors)\n",
    "# plt.title('Daily Sharpe Ratios')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Sharpe Ratio')\n",
    "# plt.grid(axis='y')\n",
    "# plt.tight_layout()\n",
    "# plt.axhline(y=0, color='black', linestyle='-')  # Add horizontal line at y=0\n",
    "# plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "\n",
    "# # Define directory and clean up the dataset_key\n",
    "# plot_dir = Path(\"plots\")\n",
    "# clean_dataset_key = dataset_key.replace(\"/\", \"_\")\n",
    "\n",
    "# # Create the plots directory if it doesn't exist\n",
    "# plot_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# # Define the save path for the plot using the cleaned key\n",
    "# plot_path = plot_dir / f\"sharpe_ratios_{clean_dataset_key}.png\"\n",
    "\n",
    "# # Save the plot\n",
    "# plt.savefig(plot_path)\n",
    "# plt.close()\n",
    "\n",
    "# # Convert the path to string and glue it\n",
    "# papermill_plot_path_str = str(plot_path)\n",
    "# sb.glue(\"papermill_plot_path\", papermill_plot_path_str, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_r, lr_p = spearmanr(preds.actual, preds.predicted)\n",
    "print(f'Information Coefficient (overall): {lr_r:.3%} (p-value: {lr_p:.8%})')\n",
    "\n",
    "# Return the Information Coefficient and its p-value\n",
    "information_coefficient = lr_r\n",
    "p_value = lr_p\n",
    "\n",
    "# information_coefficient = papermill_information_coefficient, p_value = papermill_p_value\n",
    "sb.glue(\"information_coefficient\", information_coefficient, display=True)\n",
    "sb.glue(\"p_value\", p_value, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quantile_signals(df, buy_threshold=0.95, sell_threshold=0.05):\n",
    "    buy_cutoff = df['predicted'].quantile(buy_threshold)\n",
    "    sell_cutoff = df['predicted'].quantile(sell_threshold)\n",
    "    \n",
    "    df['signal'] = 0  # Neutral by default\n",
    "    df.loc[df['predicted'] >= buy_cutoff, 'signal'] = 1  # Buy\n",
    "    df.loc[df['predicted'] <= sell_cutoff, 'signal'] = -1  # Sell\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "preds = add_quantile_signals(preds, \\\n",
    "    buy_threshold=0.95, sell_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import backtrader as bt\n",
    "# import backtrader.analyzers as btanalyzers\n",
    "# from pypfopt import EfficientFrontier, expected_returns, risk_models\n",
    "# import pyfolio as pf\n",
    "# import yfinance as yf\n",
    "\n",
    "# # Data Class for Predictions\n",
    "# class PandasPredictions(bt.feeds.PandasData):\n",
    "#     lines = ('signal',)\n",
    "#     params = (\n",
    "#         ('signal', -1),\n",
    "#         ('open', 'FEATURE_open'),\n",
    "#         ('high', 'FEATURE_high'),\n",
    "#         ('low', 'FEATURE_low'),\n",
    "#         ('close', 'FEATURE_close'),\n",
    "#         ('volume', 'FEATURE_volume')\n",
    "#     )\n",
    "\n",
    "# # Function to optimize weights using PyPortfolioOpt\n",
    "# def optimize_weights(datas):\n",
    "#     prices = {}\n",
    "    \n",
    "#     for data in datas:\n",
    "#         s = pd.Series(data.close.array, index=data.datetime.array, name=data._name)\n",
    "#         prices[data._name] = s\n",
    "\n",
    "#     df = pd.DataFrame(index=prices[next(iter(prices))].index)\n",
    "\n",
    "#     for ticker, s in prices.items():\n",
    "#         df = df.merge(s, left_index=True, right_index=True, \\\n",
    "#             how='left').rename(columns={s.name: ticker})\n",
    "\n",
    "#     df = df.dropna()\n",
    "\n",
    "#     mu = expected_returns.mean_historical_return(df)\n",
    "#     S = risk_models.sample_cov(df)\n",
    "#     ef = EfficientFrontier(mu, S, solver=\"SCS\", verbose=True)\n",
    "#     weights = ef.max_sharpe(risk_free_rate=0.005)\n",
    "#     return ef.clean_weights()\n",
    "\n",
    "\n",
    "\n",
    "# # Strategy Class\n",
    "# class TradeAndRebalanceStrategy(bt.Strategy):\n",
    "#     lines = ('benchmark',)  # Added benchmark line here\n",
    "    \n",
    "#     params = (\n",
    "#         ('stop_loss', 0.05),  # Stop loss percentage (5%)\n",
    "#         ('take_profit', 0.10)  # Take profit percentage (10%)\n",
    "#     )\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.rebalance_days = 0\n",
    "#         self.max_loss = -0.15\n",
    "#         self.start_cash = self.broker.get_cash()\n",
    "#         self.benchmark_data = self.getdatabyname(\"S&P 500\")\n",
    "#         self.orders = {}  # to store buy order references\n",
    "\n",
    "#     def log(self, txt, dt=None):\n",
    "#         ''' Logging function for the strategy. It logs the date and the message provided. '''\n",
    "#         dt = dt or self.datas[0].datetime.date(0)\n",
    "#         print(f\"{dt.isoformat()}, {txt}\")\n",
    "\n",
    "#     def notify_order(self, order):\n",
    "#         # If an order is completed, remove it from the orders dict\n",
    "#         if order.status == order.Completed:\n",
    "#             if order.ref in self.orders:\n",
    "#                 del self.orders[order.ref]\n",
    "\n",
    "#     def next(self):\n",
    "#         # Update benchmark line at each step\n",
    "#         self.lines.benchmark[0] = self.benchmark_data.close[0] \n",
    "\n",
    "#         if (self.broker.get_cash() - self.start_cash) / self.start_cash <= self.max_loss:\n",
    "#             return\n",
    "        \n",
    "#         for data in self.datas:\n",
    "#             if data._name == \"S&P 500\":  # Skip the benchmark\n",
    "#                 continue\n",
    "\n",
    "#             if data.signal[0] == 1:\n",
    "#                 order = self.buy(data)\n",
    "#                 self.orders[order.ref] = order\n",
    "                \n",
    "#                 # Setting stop-loss and take-profit levels\n",
    "#                 stop_price = data.close[0] * (1.0 - self.params.stop_loss)\n",
    "#                 limit_price = data.close[0] * (1.0 + self.params.take_profit)\n",
    "                \n",
    "#                 self.sell(data=data, exectype=bt.Order.Stop, price=stop_price, parent=order.ref)\n",
    "#                 self.sell(data=data, exectype=bt.Order.Limit, price=limit_price, parent=order.ref)\n",
    "                \n",
    "#             elif data.signal[0] == -1:\n",
    "#                 self.sell(data)\n",
    "\n",
    "#         if self.rebalance_days == 0:\n",
    "#             weights = optimize_weights([data for data in self.datas if data._name != \"S&P 500\"])\n",
    "#             for asset, weight in weights.items():\n",
    "#                 if weight > 0.30:\n",
    "#                     weights[asset] = 0.30\n",
    "            \n",
    "#             for data in self.datas:\n",
    "#                 if data._name == \"S&P 500\":\n",
    "#                     continue\n",
    "#                 if data._name in weights:\n",
    "#                     self.order_target_percent(data, target=weights[data._name])\n",
    "#                 else:\n",
    "#                     self.close(data)\n",
    "#             self.rebalance_days = 20\n",
    "#         else:\n",
    "#             self.rebalance_days -= 1\n",
    "\n",
    "#         benchmark_return = (self.benchmark_data.close[0] - \\\n",
    "#             self.benchmark_data.close[-1]) / self.benchmark_data.close[-1]\n",
    "#         self.log(f\"Benchmark Return: {benchmark_return * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# # Fetch S&P 500 data using yfinance\n",
    "# def fetch_data(ticker, start_date, end_date):\n",
    "#     df = yf.download(ticker, start=start_date, end=end_date)\n",
    "#     return df\n",
    "\n",
    "# # Assume preds is defined somewhere earlier in your code\n",
    "# start_date = preds.index.get_level_values(1).min()\n",
    "# end_date = preds.index.get_level_values(1).max()\n",
    "# sp500_data = fetch_data('^GSPC', start_date, end_date)\n",
    "\n",
    "# # Convert it into Backtrader format\n",
    "# benchmark = bt.feeds.PandasData(dataname=sp500_data, name=\"S&P 500\")\n",
    "\n",
    "# cerebro = bt.Cerebro()\n",
    "# cerebro.broker.setcommission(commission=0.001)\n",
    "# cerebro.addanalyzer(btanalyzers.PyFolio, _name='pyfolio')\n",
    "# cerebro.adddata(benchmark)\n",
    "\n",
    "# your_data_dict = {ticker: preds.xs(ticker) for ticker in preds.index.get_level_values(0).unique()}\n",
    "# for ticker, data_df in your_data_dict.items():\n",
    "#     data = PandasPredictions(dataname=data_df, name=ticker)\n",
    "#     cerebro.adddata(data)\n",
    "\n",
    "# cerebro.addstrategy(TradeAndRebalanceStrategy)\n",
    "# results = cerebro.run()\n",
    "\n",
    "# # Performance Analysis\n",
    "# returns, positions, transactions, gross_lev \\\n",
    "#     = results[0].analyzers.pyfolio.get_pf_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantstats as qs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "\n",
    "# Assuming 'returns' contains the daily percentage returns of your strategy\n",
    "# For example:\n",
    "# returns = [0.01, -0.02, 0.015, ...]  # Replace this with your actual returns data\n",
    "\n",
    "# Extend the Quantstats reports to consider the entire dataframe\n",
    "qs.extend_pandas()\n",
    "\n",
    "# # # Print extended, in-depth performance stats\n",
    "# qs.reports.full(returns)\n",
    "\n",
    "# Print only the metrics\n",
    "qs.reports.metrics(returns)\n",
    "\n",
    "# # Plotting various graphs\n",
    "# qs.plots.snapshot(returns, title='Performance Snapshot')  # Snapshot of the performance\n",
    "# qs.plots.monthly_heatmap(returns)  # Monthly returns heatmap\n",
    "# qs.plots.yearly_returns(returns)   # Yearly returns\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
