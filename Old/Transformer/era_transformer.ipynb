{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerapi import NumerAPI\n",
    "napi = NumerAPI()\n",
    "\n",
    "# napi.download_dataset(\"v4.1/train.parquet\", \"./data/train.parquet\")\n",
    "# napi.download_dataset(\"v4.1/validation.parquet\", \"./data/validation.parquet\")\n",
    "# napi.download_dataset(\"v4.1/live.parquet\", \"../data/live.parquet\")\n",
    "# napi.download_dataset(\"v4.1/live_example_preds.parquet\", \"./data/live_example_preds.parquet\")\n",
    "# napi.download_dataset(\"v4.1/validation_example_preds.parquet\", \"./data/validation_example_preds.parquet\")\n",
    "# napi.download_dataset(\"v4.1/features.json\", \"./data/features.json\")\n",
    "# napi.download_dataset(\"v4.1/meta_model.parquet\", \"./data/meta_model.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import gc, os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths to the downloaded datasets, model, and hyperparameters\n",
    "data_dir = Path('data/')\n",
    "model_dir = Path('model/')\n",
    "best_hyperparams_dir = Path('best_hyperparams/')\n",
    "study_dir = Path('study/')\n",
    "\n",
    "# Create directories if they do not exist\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "best_hyperparams_dir.mkdir(parents=True, exist_ok=True)\n",
    "study_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"features.json\") as f:\n",
    "    features_meta = json.load(f)\n",
    "\n",
    "features_to_load = features_meta[\"feature_sets\"][\"small\"] # medium or all features\n",
    "\n",
    "live = pd.read_parquet(data_dir / \"live.parquet\")\n",
    "\n",
    "cols_to_ignore = [\n",
    "    c for c in live.columns if (c not in features_to_load and \"feature_\" in c)\n",
    "]\n",
    "cols_to_load = [c for c in live.columns if c not in cols_to_ignore]\n",
    "\n",
    "train = pd.read_parquet(data_dir / \"train.parquet\", columns=cols_to_load)\n",
    "validation = pd.read_parquet(data_dir / \"validation.parquet\", columns=cols_to_load)\n",
    "live = pd.read_parquet(data_dir / \"live.parquet\", columns=cols_to_load)\n",
    "\n",
    "\n",
    "live_example_preds = pd.read_parquet(data_dir / \"live_example_preds.parquet\")\n",
    "validation_example_preds = pd.read_parquet(data_dir / \"validation_example_preds.parquet\")\n",
    "meta_model = pd.read_parquet(data_dir / \"meta_model.parquet\")\n",
    "\n",
    "assert validation.shape[0] == validation_example_preds.shape[0]\n",
    "\n",
    "\n",
    "# # Convert era to integer\n",
    "# train[\"era_int\"] = train[\"era\"].astype(int)\n",
    "# validation[\"era_int\"] = validation[\"era\"].astype(int)\n",
    "# gc.collect()\n",
    "\n",
    "# # # assert live.shape[0] == live_example_preds.shape[0]\n",
    "# # assert validation.shape[0] == meta_model.shape[0]\n",
    "\n",
    "\n",
    "feature_names = [f for f in train.columns if \"feature_\" in f]\n",
    "feature_names = [f for f in feature_names if f in features_to_load]\n",
    "target_names = [t for t in train.columns if \"target_\" in t] #[:5]\n",
    "\n",
    "# TARGET_NAME = target_names[0]\n",
    "# PREDICTION_NAME = \"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_NAME = target_names[0]\n",
    "PREDICTION_NAME = \"prediction\"\n",
    "\n",
    "# # all eras of TARGET_NAME must be present in diagnostics\n",
    "# validation = validation.dropna(subset=[TARGET_NAME], axis=0).copy()\n",
    "# # validation[TARGET_NAME] = validation[TARGET_NAME].fillna(0.5)\n",
    "\n",
    "# Get the indices where TARGET_NAME is not NaN\n",
    "valid_indices = validation[~validation[TARGET_NAME].isna()].index\n",
    "\n",
    "# Use these indices to subset validation\n",
    "validation = validation.loc[valid_indices].copy()\n",
    "\n",
    "# Use the same indices to subset validation_example_preds\n",
    "validation_example_preds = validation_example_preds.loc[valid_indices]\n",
    "\n",
    "assert validation.shape[0] == validation_example_preds.shape[0]\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "train[\"era_int\"] = train[\"era\"].astype(int)\n",
    "validation[\"era_int\"] = validation[\"era\"].astype(int)\n",
    "gc.collect()\n",
    "\n",
    "train[feature_names] = train[feature_names].fillna(-2)\n",
    "validation[feature_names] = validation[feature_names].fillna(-2)\n",
    "gc.collect()\n",
    "\n",
    "# use a better method to handle NaN in targets\n",
    "train[target_names] = train[target_names].fillna(0.5)\n",
    "validation[target_names] = validation[target_names].fillna(0.5)\n",
    "gc.collect()\n",
    "\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_VALUE = -1\n",
    "MAX_LEN = 6000\n",
    "FEATURE_DIM = len(feature_names)\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(target_names)\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [00:01<00:00, 401.54it/s]\n",
      "100%|██████████| 574/574 [00:00<00:00, 1812899.47it/s]\n",
      "100%|██████████| 492/492 [00:01<00:00, 365.58it/s]\n",
      "100%|██████████| 492/492 [00:00<00:00, 1930399.97it/s]\n"
     ]
    }
   ],
   "source": [
    "def pad_sequence(inputs, padding_value=-1, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = max([input.shape[0] for input in inputs])\n",
    "    padded_inputs = []\n",
    "    masks = []\n",
    "    for input in inputs:\n",
    "        pad_len = max_len - input.shape[0]\n",
    "        padded_input = F.pad(input, (0, 0, 0, pad_len), value=padding_value)\n",
    "        mask = torch.ones((input.shape[0], 1), dtype=torch.float)\n",
    "        masks.append(\n",
    "            torch.cat((mask, torch.zeros((pad_len, 1), dtype=torch.float)), dim=0)\n",
    "        )\n",
    "        padded_inputs.append(padded_input)\n",
    "    return torch.stack(padded_inputs), torch.stack(masks)\n",
    "\n",
    "\n",
    "def convert_to_torch(era, data):\n",
    "\n",
    "    inputs = torch.from_numpy(\n",
    "                data[feature_names].values.astype(np.int8))\n",
    "    labels = torch.from_numpy(\n",
    "                data[target_names].values.astype(np.float32))\n",
    "\n",
    "    padded_inputs, masks_inputs = pad_sequence(\n",
    "            [inputs], padding_value=PADDING_VALUE, max_len=MAX_LEN)\n",
    "    padded_labels, masks_labels = pad_sequence(\n",
    "            [labels], padding_value=PADDING_VALUE, max_len=MAX_LEN)\n",
    "\n",
    "    return {\n",
    "        era: (\n",
    "            padded_inputs, # features\n",
    "            padded_labels,\n",
    "            masks_inputs\n",
    "        )\n",
    "    }\n",
    "\n",
    "def get_era2data(df):\n",
    "    res = Parallel(n_jobs=-1, prefer=\"threads\")(\n",
    "        delayed(convert_to_torch)(era, data)\n",
    "        for era, data in tqdm(df.groupby(\"era_int\")))\n",
    "    era2data = {}\n",
    "    for r in tqdm(res):\n",
    "        era2data.update(r)\n",
    "    return era2data\n",
    "\n",
    "## dataloader\n",
    "era2data_train = get_era2data(train)\n",
    "era2data_validation = get_era2data(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([2, 6000, 32])\n",
      "Output Shape: torch.Size([2, 6000, 36])\n"
     ]
    }
   ],
   "source": [
    "from model import Transformer\n",
    "\n",
    "def test_model():\n",
    "\n",
    "    inputs = [\n",
    "        torch.randint(0, 4, (5, FEATURE_DIM)).float(),\n",
    "        torch.randint(0, 4, (3, FEATURE_DIM)).float(),\n",
    "    ]\n",
    "    labels = [\n",
    "        torch.randint(0, 2, (5, OUTPUT_DIM)).float(),\n",
    "        torch.randint(0, 2, (3, OUTPUT_DIM)).float(),\n",
    "    ]\n",
    "\n",
    "    padded_inputs, masks_inputs = pad_sequence(inputs, \\\n",
    "                                               padding_value=0, max_len=MAX_LEN)\n",
    "    padded_labels, masks_labels = pad_sequence(labels, \\\n",
    "                                               padding_value=0, max_len=MAX_LEN)\n",
    "\n",
    "    transformer = Transformer(\n",
    "        input_dim=FEATURE_DIM,\n",
    "        d_model=HIDDEN_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        max_len=MAX_LEN,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = transformer(padded_inputs, masks_inputs)\n",
    "\n",
    "    assert torch.isnan(outputs).sum() == 0\n",
    "    assert outputs.shape[:2] == padded_inputs.shape[:2]\n",
    "    assert outputs.shape[-1] == len(target_names)\n",
    "\n",
    "    print(\"Input Shape:\", padded_inputs.shape)\n",
    "    print(\"Output Shape:\", outputs.shape)\n",
    "\n",
    "    del transformer\n",
    "    del inputs, labels\n",
    "    del padded_inputs, masks_inputs, padded_labels, masks_labels\n",
    "    del outputs\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearsonr in torch differentiable\n",
    "def pearsonr(x, y):\n",
    "    mx = x.mean()\n",
    "    my = y.mean()\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = torch.sum(xm * ym)\n",
    "    r_den = torch.sqrt(torch.sum(xm ** 2) * torch.sum(ym ** 2))\n",
    "    r = r_num / r_den\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(outputs, criterion, padded_labels, masks_inputs, \\\n",
    "                padded_inputs=None, target_weight_softmax=None):\n",
    "\n",
    "    # MSE on all targets; additionally, on primary target\n",
    "    if target_weight_softmax is not None:\n",
    "        _mse = criterion(\n",
    "            outputs * masks_inputs * target_weight_softmax,\n",
    "            padded_labels * masks_inputs * target_weight_softmax\n",
    "        ) * 0.1\n",
    "\n",
    "    else:\n",
    "        _mse = criterion(outputs * masks_inputs, padded_labels * masks_inputs) * 0.1\n",
    "\n",
    "    _mse += criterion(outputs[:, 0] * masks_inputs, padded_labels[:, 0] * masks_inputs)\n",
    "\n",
    "    # Corr with only primary target; adjust as needed\n",
    "    corr = pearsonr(\n",
    "        outputs[0][:, 0][masks_inputs.view(-1).nonzero()].view(-1, 1),\n",
    "        padded_labels[0][:, 0][masks_inputs.view(-1).nonzero()].view(-1, 1),\n",
    "    )\n",
    "\n",
    "    loss = _mse - corr #+ some_complex_constraints\n",
    "    return loss, _mse, corr\n",
    "\n",
    "# Training loop\n",
    "def train_on_batch(transformer, criterion, optimizer, batch):\n",
    "\n",
    "    padded_inputs = batch[0].to(device=device)\n",
    "    padded_labels = batch[1].to(device=device)\n",
    "    masks_inputs = batch[2].to(device=device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = transformer(padded_inputs / 4.0, masks_inputs)\n",
    "    # print(outputs)\n",
    "\n",
    "    target_weight_softmax = None\n",
    "    #random_weights = torch.rand(padded_labels.shape[-1], device=device)\n",
    "    #target_weight_softmax = F.softmax(random_weights)\n",
    "\n",
    "    loss, _mse, _corr = calculate_loss(outputs, criterion, padded_labels, masks_inputs, \\\n",
    "                                       target_weight_softmax=target_weight_softmax)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), _mse.item(), _corr.item()\n",
    "\n",
    "\n",
    "def evaluate_on_batch(transformer, criterion, batch):\n",
    "\n",
    "    padded_inputs = batch[0].to(device=device)\n",
    "    padded_labels = batch[1].to(device=device)\n",
    "    masks_inputs = batch[2].to(device=device)\n",
    "\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = transformer(padded_inputs / 4.0, masks_inputs)\n",
    "        # print(outputs)\n",
    "        loss, _mse, _corr = calculate_loss(outputs, criterion, padded_labels, masks_inputs)\n",
    "        \n",
    "        # Convert outputs to numpy\n",
    "        preds = outputs[0][masks_inputs.view(-1).nonzero()].squeeze(1).cpu().numpy()\n",
    "        # print(preds)\n",
    "\n",
    "    return loss.item(), _mse.item(), _corr.item(), preds\n",
    "\n",
    "\n",
    "def metrics_on_batch(era_scores):\n",
    "    era_scores = pd.Series(era_scores)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mean_correlation = np.mean(era_scores)\n",
    "    std_deviation = np.std(era_scores)\n",
    "    sharpe_ratio = mean_correlation / std_deviation\n",
    "    max_dd = (era_scores.cummax() - era_scores).max() # from calculate_metrics\n",
    "\n",
    "    # Smart Sharpe: Modified Sharpe ratio that also considers the instability of scores over time,\n",
    "    # penalizing models with high score instability even if their mean score is high\n",
    "    smart_sharpe = mean_correlation / (std_deviation + np.std(era_scores.diff()))\n",
    "    \n",
    "    # Autocorrelation: Measure of the correlation of the series with a lagged version of itself\n",
    "    autocorrelation = era_scores.autocorr()\n",
    "\n",
    "    metrics = pd.Series({\n",
    "        'mean_correlation': mean_correlation,\n",
    "        'std_deviation': std_deviation,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'smart_sharpe': smart_sharpe,\n",
    "        'autocorrelation': autocorrelation,\n",
    "        'max_dd': max_dd, # added from calculate_metrics\n",
    "        'min_correlation': era_scores.min(), # added from calculate_metrics\n",
    "        'max_correlation': era_scores.max(), # added from calculate_metrics\n",
    "    })\n",
    "\n",
    "    # Cleanup\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_model(transformer, criterion, optimizer, scheduler, \\\n",
    "                num_epochs, patience, train_loader, val_loader, is_lr_scheduler=True):\n",
    "    best_loss = float('inf')\n",
    "    best_corr = None\n",
    "    best_model = None\n",
    "    best_outputs = None\n",
    "    no_improve_epoch = 0\n",
    "\n",
    "    epoch_progress = tqdm(range(num_epochs), desc=\"Epochs\", position=0, leave=False)\n",
    "\n",
    "    for epoch in epoch_progress:\n",
    "        total_loss = []\n",
    "        total_corr = []\n",
    "\n",
    "        # Training\n",
    "        for era_num in tqdm(train_loader, desc=\"Training\", leave=False, position=1):\n",
    "            batch = train_loader[era_num]\n",
    "            loss, _mse, _corr = train_on_batch(transformer, criterion, optimizer, batch)\n",
    "            total_loss.append(loss)\n",
    "            total_corr.append(_corr)\n",
    "\n",
    "        # Adjust learning rate if is_lr_scheduler is True\n",
    "        if is_lr_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        transformer.eval()\n",
    "        val_total_loss = []\n",
    "        val_total_corr = []\n",
    "        val_total_outputs = {}\n",
    "        with torch.no_grad():\n",
    "            for era_num in tqdm(val_loader, desc=\"Validation\", leave=False, position=2):\n",
    "                batch = val_loader[era_num]\n",
    "                loss, _mse, _corr, outputs = evaluate_on_batch(transformer, criterion, batch)\n",
    "                # print(outputs)\n",
    "                val_total_loss.append(loss)\n",
    "                val_total_corr.append(_corr)\n",
    "                val_total_outputs[era_num] = outputs\n",
    "\n",
    "        # Early stopping check\n",
    "        val_loss = np.mean(val_total_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_corr = val_total_corr.copy()\n",
    "            best_model = transformer.state_dict().copy()\n",
    "            best_outputs = val_total_outputs.copy()\n",
    "            no_improve_epoch = 0\n",
    "        else:\n",
    "            no_improve_epoch += 1\n",
    "            if no_improve_epoch >= patience:\n",
    "                epoch_progress.set_description(f'Early stopping at epoch {epoch+1}')\n",
    "                epoch_progress.refresh()\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    # Save the best model state\n",
    "    torch.save(best_model, data_dir / \"transformer_best.pth\")\n",
    "\n",
    "    return transformer, best_corr, best_outputs # best_outputs for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model, loss function, and optimizer\n",
    "\n",
    "# gc.collect()\n",
    "# transformer = Transformer(\n",
    "#     input_dim=FEATURE_DIM,\n",
    "#     d_model=HIDDEN_DIM,\n",
    "#     output_dim=OUTPUT_DIM,\n",
    "#     num_heads=NUM_HEADS,\n",
    "#     num_layers=NUM_LAYERS,\n",
    "# )\n",
    "\n",
    "# # load model from checkpoint\n",
    "# if (data_dir / \"transformer.pth\").is_file():\n",
    "#     transformer.load_state_dict(torch.load(data_dir / \"transformer.pth\"))\n",
    "\n",
    "# transformer.to(device=device)\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "\n",
    "# # Number of training iterations\n",
    "# # Train for longer with low LR\n",
    "\n",
    "# num_epochs = 1\n",
    "# patience = 5\n",
    "\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# scheduler = StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "# transformer, best_corr, preds = train_model(transformer, criterion, optimizer, scheduler, \\\n",
    "#                                     num_epochs, patience, era2data_train, \\\n",
    "#                                     era2data_validation, is_lr_scheduler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_and_merge(validation, val_total_outputs, validation_example_preds, meta_model):\n",
    "    \n",
    "    validation[\"example_preds\"] = validation_example_preds\n",
    "    # Initialize an empty list to store predictions\n",
    "    all_predictions = []\n",
    "\n",
    "    # Iterate over sorted era numbers\n",
    "    for era_num in sorted(val_total_outputs.keys()):\n",
    "        # Get the predictions for the current era\n",
    "        predictions = val_total_outputs[era_num]\n",
    "        \n",
    "        # We only need the first column of each prediction\n",
    "        predictions = predictions[:, 0]\n",
    "        \n",
    "        # Add the predictions to the list\n",
    "        all_predictions.extend(predictions)\n",
    "\n",
    "    # Now, all_predictions is a single list containing all predictions in order\n",
    "    # Convert it to a numpy array\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    # Add the predictions as a new column to the validation DataFrame\n",
    "    validation[PREDICTION_NAME] = all_predictions\n",
    "    \n",
    "\n",
    "    # Reset the index and only keep the required columns\n",
    "    diagnosis = validation[[\"era_int\", PREDICTION_NAME, \\\n",
    "                            TARGET_NAME, \"example_preds\"]].reset_index()\n",
    "\n",
    "    # Merge diagnosis with meta model\n",
    "    combined = pd.merge(\n",
    "        diagnosis,\n",
    "        meta_model,\n",
    "        on=[\"id\"],\n",
    "        how=\"right\"\n",
    "    ).dropna(axis=0)\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "def unif(df):\n",
    "    \"\"\"from example scripts\"\"\"\n",
    "    x = (df.rank(method=\"first\") - 0.5) / len(df)\n",
    "    return pd.Series(x, index=df.index)\n",
    "\n",
    "\n",
    "def calculate_correlations(combined, PREDICTION_NAME):\n",
    "\n",
    "    pred2meta_model_corr = (\n",
    "        combined[[\"era_int\", \"numerai_meta_model\", PREDICTION_NAME]]\n",
    "        .groupby(\"era_int\")\n",
    "        .progress_apply(\n",
    "            lambda d: unif(d[PREDICTION_NAME]).corr(d[\"numerai_meta_model\"])\n",
    "        )\n",
    "        .sort_index()\n",
    "        .rename(\"pred2meta_model_corr\")\n",
    "    )\n",
    "\n",
    "    example_preds_corr = (\n",
    "        combined[[\"era_int\", \"example_preds\", PREDICTION_NAME]]\n",
    "        .groupby(\"era_int\")\n",
    "        .progress_apply(\n",
    "            lambda d: unif(d[PREDICTION_NAME]).corr(d[\"example_preds\"])\n",
    "        )\n",
    "        .sort_index()\n",
    "        .rename(\"pred2example_preds_corr\")\n",
    "    )\n",
    "\n",
    "    example2meta_model_corr = (\n",
    "        combined[[\"era_int\", \"example_preds\", \"numerai_meta_model\"]]\n",
    "        .groupby(\"era_int\")\n",
    "        .progress_apply(\n",
    "            lambda d: unif(d[\"numerai_meta_model\"]).corr(d[\"example_preds\"])\n",
    "        )\n",
    "        .sort_index()\n",
    "        .rename(\"example2meta_model_corr\")\n",
    "    )\n",
    "\n",
    "    return pred2meta_model_corr, example_preds_corr, example2meta_model_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# NUM_EPOCHS = 1\n",
    "# PATIENCE = 5\n",
    "\n",
    "# def objective(trial, validation=validation, validation_example_preds=validation_example_preds, \\\n",
    "#               meta_model=meta_model):\n",
    "#     # Define the model, loss function, and optimizer\n",
    "#     print(f\"\\n--- Starting Trial: {trial.number + 1} ---\")\n",
    "\n",
    "#     _ = gc.collect()\n",
    "\n",
    "#     # suggest hyperparameters\n",
    "#     num_heads = trial.suggest_int(\"num_heads\", 1, 5)\n",
    "#     hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 256, step=2)\n",
    "#     num_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
    "#     lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "#     transformer = Transformer(\n",
    "#         input_dim=FEATURE_DIM,\n",
    "#         d_model=hidden_dim,\n",
    "#         output_dim=OUTPUT_DIM,\n",
    "#         num_heads=num_heads,\n",
    "#         num_layers=num_layers,\n",
    "#     )\n",
    "\n",
    "#     # # load model from checkpoint\n",
    "#     # if (model_dir / \"transformer.pth\").is_file():\n",
    "#     #     transformer.load_state_dict(torch.load(model_dir / \"transformer.pth\"))\n",
    "\n",
    "#     transformer.to(device=device)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(transformer.parameters(), lr=lr)\n",
    "#     scheduler = StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "#     # Number of training iterations\n",
    "#     num_epochs = NUM_EPOCHS \n",
    "#     patience = PATIENCE\n",
    "#     transformer, best_corr, outputs = train_model(transformer, criterion, optimizer, scheduler, \\\n",
    "#                                         num_epochs, patience, era2data_train, \\\n",
    "#                                         era2data_validation, is_lr_scheduler=True)\n",
    "    \n",
    "#     # # print(f'Validation shape: {validation.shape}')\n",
    "#     # print(outputs)\n",
    "#     metrics = metrics_on_batch(best_corr)\n",
    "\n",
    "#     trial.set_user_attr(\"transformer\", transformer)\n",
    "\n",
    "\n",
    "#     # diagnostic = add_predictions_and_merge(validation, outputs, validation_example_preds, meta_model)\n",
    "#     # pred2meta_model_corr, example_preds_corr, example2meta_model_corr = \\\n",
    "#     #             calculate_correlations(diagnostic, PREDICTION_NAME)\n",
    "#     # # print(f'diagnostic shape after: {diagnostic.shape} and col names: {diagnostic.columns}')\n",
    "\n",
    "#     ### Save model and parameters if it's the best so far\n",
    "#     # if trial.value is None or trial.value < study.best_value:\n",
    "#     #     torch.save(transformer, model_dir / f\"best_model_trial_{trial.number}.pth\")\n",
    "#     #     with open(best_hyperparams_dir / f\"best_params_trial_{trial.number}.json\", 'w') as f:\n",
    "#     #         json.dump(trial.params, f)\n",
    "    \n",
    "#     return -metrics['sharpe_ratio']  # return negative correlation because optuna minimizes the objective function\n",
    "\n",
    "# # Callback to save the best model and its hyperparameters after each trial\n",
    "# def callback(study, trial):\n",
    "#     print(f\"\\n--- Trial {trial.number + 1} finished ---\")\n",
    "#     print(f\"Value: {trial.value} and parameters: {trial.params}\")\n",
    "#     print(f\"Best is trial {study.best_trial.number} with value: {study.best_trial.value}\\n\")\n",
    "    \n",
    "#     # If the trial is the best so far, save the model and hyperparameters\n",
    "#     if study.best_trial.number == trial.number:\n",
    "#         best_model = trial.user_attrs[\"transformer\"]\n",
    "#         torch.save(best_model, model_dir / \"best_model.pth\")\n",
    "#         with open(best_hyperparams_dir / \"best_params.json\", 'w') as f:\n",
    "#             json.dump(trial.params, f)\n",
    "\n",
    "# study = optuna.create_study(study_name='Maximizing the Sharpe', direction='minimize', \\\n",
    "#                             storage=f'sqlite:///{study_dir}/study.db', load_if_exists=True)\n",
    "# study.optimize(objective, n_trials=25, callbacks=[callback])\n",
    "# gc.collect()  # manual garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "PATIENCE = 5\n",
    "\n",
    "\n",
    "def objective(trial, validation=validation, validation_example_preds=validation_example_preds, \\\n",
    "              meta_model=meta_model):\n",
    "    # Define the model, loss function, and optimizer\n",
    "    print(f\"\\n--- Starting Trial: {trial.number + 1} ---\")\n",
    "\n",
    "    _ = gc.collect()\n",
    "\n",
    "    # suggest hyperparameters\n",
    "    num_heads = trial.suggest_int(\"num_heads\", 1, 5)\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 256, step=2)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    transformer = Transformer(\n",
    "        input_dim=FEATURE_DIM,\n",
    "        d_model=hidden_dim,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "    )\n",
    "\n",
    "    # # load model from checkpoint\n",
    "    # if (model_dir / \"transformer.pth\").is_file():\n",
    "    #     transformer.load_state_dict(torch.load(model_dir / \"transformer.pth\"))\n",
    "\n",
    "    transformer.to(device=device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(transformer.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "    # Number of training iterations\n",
    "    num_epochs = NUM_EPOCHS \n",
    "    patience = PATIENCE\n",
    "    transformer, best_corr, outputs = train_model(transformer, criterion, optimizer, scheduler, \\\n",
    "                                        num_epochs, patience, era2data_train, \\\n",
    "                                        era2data_validation, is_lr_scheduler=True)\n",
    "    \n",
    "    metrics = metrics_on_batch(best_corr)\n",
    "\n",
    "    # diagnostic = add_predictions_and_merge(validation, outputs, validation_example_preds, meta_model)\n",
    "    # pred2meta_model_corr, example_preds_corr, example2meta_model_corr = \\\n",
    "    #             calculate_correlations(diagnostic, PREDICTION_NAME)\n",
    "    \n",
    "    # # print(f'diagnostic shape after: {diagnostic.shape} and col names: {diagnostic.columns}')\n",
    "\n",
    "    # Save the transformer model after each trial\n",
    "\n",
    "    torch.save(transformer, model_dir / f\"model_trial_{trial.number}.pth\")\n",
    "\n",
    "    return -metrics['sharpe_ratio']  # return negative correlation because optuna minimizes the objective function\n",
    "\n",
    "\n",
    "# Callback to save the best model and its hyperparameters after each trial\n",
    "def callback(study, trial):\n",
    "    print(f\"\\n--- Trial {trial.number + 1} finished ---\")\n",
    "    print(f\"Value: {trial.value} and parameters: {trial.params}\")\n",
    "    print(f\"Best is trial {study.best_trial.number} with value: {study.best_trial.value}\\n\")\n",
    "    \n",
    "    # If the trial is the best so far, rename the saved model file and save the hyperparameters\n",
    "    if study.best_trial.number == trial.number:\n",
    "        # Rename the saved model file\n",
    "        os.rename(model_dir / f\"model_trial_{trial.number}.pth\", model_dir / \"best_model.pth\")\n",
    "\n",
    "        # Save the hyperparameters\n",
    "        with open(best_hyperparams_dir / \"best_params.json\", 'w') as f:\n",
    "            json.dump(trial.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Uncomment to train #####\n",
    "\n",
    "# study = optuna.create_study(study_name='Maximizing the Sharpe', direction='minimize', \\\n",
    "#                             storage=f'sqlite:///{study_dir}/study.db', load_if_exists=True)\n",
    "\n",
    "# study.optimize(objective, n_trials=25, callbacks=[callback])\n",
    "# gc.collect()  # manual garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model_performance(pred2meta_model_corr, example_preds_corr, example2meta_model_corr):\n",
    "    # Use the metrics to generate a qualitative assessment of the model's performance\n",
    "    print(\"=== Model Performance Analysis ===\")\n",
    "\n",
    "    # Analyze correlation to the meta model\n",
    "    if pred2meta_model_corr.mean() > 0:\n",
    "        print(f\"Positively correlated with the meta model. Average correlation: {pred2meta_model_corr.mean():.4f}.\")\n",
    "    else:\n",
    "        print(f\"Negatively correlated with the meta model. Average correlation: {pred2meta_model_corr.mean():.4f}.\")\n",
    "\n",
    "    # Analyze correlation to the example predictions\n",
    "    if example_preds_corr.mean() > 0:\n",
    "        print(f\"Positively correlated with the example predictions. Average correlation: {example_preds_corr.mean():.4f}.\")\n",
    "    else:\n",
    "        print(f\"Negatively correlated with the example predictions. Average correlation: {example_preds_corr.mean():.4f}.\")\n",
    "\n",
    "    # Analyze correlation between the meta model and the example predictions\n",
    "    if example2meta_model_corr.mean() > 0:\n",
    "        print(f\"Meta model's predictions are positively correlated with the example predictions. Average correlation: {example2meta_model_corr.mean():.4f}.\")\n",
    "    else:\n",
    "        print(f\"Meta model's predictions are negatively correlated with the example predictions. Average correlation: {example2meta_model_corr.mean():.4f}.\")\n",
    "\n",
    "    print(\"=== End of Model Performance Analysis ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_dir / \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788bcab492474ab69fcc33d7f59cd46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_on_era2data(era2data, transformer, criterion, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Currently returns only primary target.\n",
    "    outputs[0][:, 0]: target_nomi_v4_20\n",
    "    \"\"\"\n",
    "    transformer.eval()\n",
    "\n",
    "    val_total_loss = []\n",
    "    val_total_corr = []\n",
    "    val_total_outputs = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for era_num in tqdm(era2data, desc=\"Validation\", leave=False, position=2):\n",
    "            batch = era2data[era_num]\n",
    "\n",
    "            # Move to specified device\n",
    "            batch = (batch[0].to(device=device), batch[1].to(device=device), batch[2].to(device=device))\n",
    "\n",
    "            # evaluate_on_batch should return loss, mse, corr, outputs\n",
    "            loss, _mse, _corr, outputs = evaluate_on_batch(transformer, criterion, batch)\n",
    "\n",
    "            # Store metrics\n",
    "            val_total_loss.append(loss)\n",
    "            val_total_corr.append(_corr)\n",
    "            val_total_outputs[era_num] = outputs\n",
    "\n",
    "    return val_total_loss, val_total_corr, val_total_outputs\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "_, _, outputs = predict_on_era2data(era2data_validation, model, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:00<00:00, 1931.06it/s]\n",
      "100%|██████████| 179/179 [00:00<00:00, 1967.69it/s]\n",
      "100%|██████████| 179/179 [00:00<00:00, 1998.26it/s]\n"
     ]
    }
   ],
   "source": [
    "diagnostic = add_predictions_and_merge(validation, outputs, validation_example_preds, meta_model)\n",
    "pred2meta_model_corr, example_preds_corr, example2meta_model_corr = \\\n",
    "            calculate_correlations(diagnostic, PREDICTION_NAME)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Performance Analysis ===\n",
      "Positively correlated with the meta model. Average correlation: 0.4074.\n",
      "Positively correlated with the example predictions. Average correlation: 0.2702.\n",
      "Meta model's predictions are positively correlated with the example predictions. Average correlation: 0.6330.\n",
      "=== End of Model Performance Analysis ===\n"
     ]
    }
   ],
   "source": [
    "analyze_model_performance(pred2meta_model_corr, example_preds_corr, example2meta_model_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_live(data):\n",
    "\n",
    "    inputs = torch.from_numpy(\n",
    "                data[feature_names].values.astype(np.int8))\n",
    "\n",
    "    padded_inputs, masks_inputs = pad_sequence(\n",
    "            [inputs], padding_value=PADDING_VALUE, max_len=MAX_LEN)\n",
    "\n",
    "    return padded_inputs, masks_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap your model with a function that takes live features and returns live predictions\n",
    "def predict(live_features: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    device = \"cpu\"\n",
    "    transformer.to(device)\n",
    "    if 0.5 in live_features[feature_names[0]]:\n",
    "        live_features[feature_names] = (live_features[feature_names] * 4.0).astype(int)\n",
    "\n",
    "    input_live, mask_live = prepare_live(live_features)\n",
    "    input_live, mask_live = input_live.to(device), mask_live.to(device)\n",
    "    preds_live = transformer(input_live/4.0, mask_live)[0][mask_live.view(-1).nonzero()].squeeze(1).detach().cpu().numpy()[:, 0]\n",
    "    print(preds_live.shape)\n",
    "    submission = pd.Series(preds_live, index=live_features.index)\n",
    "    return submission.to_frame(\"prediction\")\n",
    "\n",
    "# Use the cloudpickle library to serialize your function\n",
    "import cloudpickle\n",
    "p = cloudpickle.dumps(predict)\n",
    "with open(\"predict_transformer.pkl\", \"wb\") as f:\n",
    "    f.write(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
