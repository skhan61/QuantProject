{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection \\\n",
    "        import mutual_info_regression\n",
    "        \n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"H5F.c\", line 509, in H5Fopen\n    unable to open file\n  File \"H5Fint.c\", line 1652, in H5F_open\n    unable to read superblock\n  File \"H5Fsuper.c\", line 632, in H5F__super_read\n    truncated file: eof = 96, sblock->base_addr = 0, stored_eof = 2048\n\nEnd of HDF5 error back trace\n\nUnable to open/create file '/home/sayem/Desktop/Project/data/assets.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sayem/Desktop/Project/04_explanatory _data_analysis_ml_dataset_building.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sayem/Desktop/Project/04_explanatory%20_data_analysis_ml_dataset_building.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Lock the file and retrieve the data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sayem/Desktop/Project/04_explanatory%20_data_analysis_ml_dataset_building.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m FileLock(lock_path):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sayem/Desktop/Project/04_explanatory%20_data_analysis_ml_dataset_building.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mwith\u001b[39;00m pd\u001b[39m.\u001b[39mHDFStore(DATA_STORE) \u001b[39mas\u001b[39;00m store:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sayem/Desktop/Project/04_explanatory%20_data_analysis_ml_dataset_building.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         alpha_101_data \u001b[39m=\u001b[39m store[\u001b[39m'\u001b[39m\u001b[39mfactors/alpha_101\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sayem/Desktop/Project/04_explanatory%20_data_analysis_ml_dataset_building.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         common_data \u001b[39m=\u001b[39m store[\u001b[39m'\u001b[39m\u001b[39mfactors/common\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/pytables.py:578\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fletcher32 \u001b[39m=\u001b[39m fletcher32\n\u001b[1;32m    577\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filters \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(mode\u001b[39m=\u001b[39mmode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/pytables.py:737\u001b[0m, in \u001b[0;36mHDFStore.open\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    732\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot open HDF5 file, which is already opened, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meven in read-only mode.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    735\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 737\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m tables\u001b[39m.\u001b[39mopen_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tables/file.py:300\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is already opened.  Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mclose it before reopening in write mode.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[1;32m    299\u001b[0m \u001b[39m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[39mreturn\u001b[39;00m File(filename, mode, title, root_uep, filters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tables/file.py:750\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m params\n\u001b[1;32m    749\u001b[0m \u001b[39m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_g_new(filename, mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    752\u001b[0m \u001b[39m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v_new\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tables/hdf5extension.pyx:484\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"H5F.c\", line 509, in H5Fopen\n    unable to open file\n  File \"H5Fint.c\", line 1652, in H5F_open\n    unable to read superblock\n  File \"H5Fsuper.c\", line 632, in H5F__super_read\n    truncated file: eof = 96, sblock->base_addr = 0, stored_eof = 2048\n\nEnd of HDF5 error back trace\n\nUnable to open/create file '/home/sayem/Desktop/Project/data/assets.h5'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from filelock import FileLock\n",
    "\n",
    "# Define the path\n",
    "DATA_STORE = Path('/home/sayem/Desktop/Project/data/assets.h5')\n",
    "lock_path = \"/tmp/assets_h5_file.lock\"  # Lock path\n",
    "\n",
    "# Lock the file and retrieve the data\n",
    "with FileLock(lock_path):\n",
    "    with pd.HDFStore(DATA_STORE) as store:\n",
    "        alpha_101_data = store['factors/alpha_101']\n",
    "        common_data = store['factors/common']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove overlapping column from common_data\n",
    "common_data = common_data.drop(columns=['ret_fwd_01d'])\n",
    "\n",
    "# Join the dataframes\n",
    "joined_data = common_data.join(alpha_101_data, \\\n",
    "    how='right', lsuffix='_alpha', rsuffix='_common')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 10000  # Adjust based on available memory\n",
    "total_chunks = len(joined_data) // CHUNK_SIZE + 1\n",
    "\n",
    "for i in range(total_chunks):\n",
    "    start_idx = i * CHUNK_SIZE\n",
    "    end_idx = (i + 1) * CHUNK_SIZE\n",
    "    chunk = joined_data.iloc[start_idx:end_idx]\n",
    "    \n",
    "    chunk.to_hdf(DATA_STORE, 'factors/concat', format='table', mode='a', \\\n",
    "        append=True, complevel=9, complib='blosc')\n",
    "    print(f\"Saved chunk {i+1} of {total_chunks}\")\n",
    "\n",
    "# Free up memory\n",
    "del joined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    concat = store['factors/concat']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
